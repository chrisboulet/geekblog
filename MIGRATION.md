# Guide de Migration GeekBlog

‚ö†Ô∏è **Note** : Ce guide est fourni pour r√©f√©rence architecturale. GeekBlog √©tant encore en d√©veloppement, l'architecture optimis√©e single-container est impl√©ment√©e directement sans migration n√©cessaire.

Pour le d√©veloppement, voir **[README_DEVELOPMENT.md](./README_DEVELOPMENT.md)**.

---

## üìã Contexte Architectural

Ce document explique comment migrer depuis une architecture microservices traditionnelle (5 containers) vers l'architecture optimis√©e GeekBlog (1 container), pour r√©f√©rence future.

## üìã Table des Mati√®res

1. [Vue d'Ensemble](#vue-densemble)
2. [Pr√©-Migration](#pr√©-migration)
3. [Migration des Donn√©es](#migration-des-donn√©es)
4. [Migration Manuelle](#migration-manuelle)
5. [Migration Automatis√©e](#migration-automatis√©e)
6. [Validation](#validation)
7. [Rollback](#rollback)
8. [FAQ](#faq)

---

## üîÑ Vue d'Ensemble

### Changements Majeurs

| Composant | Avant | Apr√®s | Impact |
|-----------|--------|-------|--------|
| **Database** | PostgreSQL | SQLite | Migration donn√©es requise |
| **Queue** | Celery + Redis | BackgroundTasks | Jobs migr√©s automatiquement |
| **Containers** | 5 (db, redis, backend, celery, frontend) | 1 | Architecture simplifi√©e |
| **Deployment** | docker-compose.yml complexe | docker run simple | Configuration simplifi√©e |
| **Memory** | 12GB+ | <500MB | 95% r√©duction |

### Compatibilit√©

‚úÖ **Pr√©serv√©**: Toutes les fonctionnalit√©s, API endpoints, donn√©es  
‚úÖ **Am√©lior√©**: Performance, simplicit√©, resource usage  
‚ö†Ô∏è **Chang√©**: M√©thode de d√©ploiement, configuration base de donn√©es  

---

## üîç Pr√©-Migration

### 1. V√©rification Version Actuelle

```bash
# V√©rifier la version actuelle
docker-compose ps
curl http://localhost:8000/api/v1/health

# Lister les projets existants
curl http://localhost:8000/api/v1/projects

# V√©rifier les donn√©es PostgreSQL
docker exec geekblog_db psql -U geekblog -d geekblogdb -c "SELECT COUNT(*) FROM projects;"
```

### 2. Backup Complet

```bash
# 1. Backup PostgreSQL
docker exec geekblog_db pg_dump -U geekblog -d geekblogdb > backup_$(date +%Y%m%d_%H%M%S).sql

# 2. Backup Redis (jobs en cours)
docker exec geekblog_redis redis-cli BGSAVE
docker cp geekblog_redis:/data/dump.rdb ./redis_backup.rdb

# 3. Backup configuration
cp .env .env.backup
cp docker-compose.yml docker-compose.yml.backup
```

### 3. Inventaire des Donn√©es

```bash
# Script d'inventaire
cat > inventory.sh << 'EOF'
#!/bin/bash
echo "=== GeekBlog Data Inventory ==="
echo "Projects:"
docker exec geekblog_db psql -U geekblog -d geekblogdb -c "SELECT id, title FROM projects;" -t

echo -e "\nTasks:"
docker exec geekblog_db psql -U geekblog -d geekblogdb -c "SELECT COUNT(*) as task_count FROM tasks;" -t

echo -e "\nJobs (Redis):"
docker exec geekblog_redis redis-cli KEYS "*" | wc -l

echo -e "\nDatabase size:"
docker exec geekblog_db psql -U geekblog -d geekblogdb -c "SELECT pg_size_pretty(pg_database_size('geekblogdb'));" -t
EOF

chmod +x inventory.sh && ./inventory.sh
```

---

## üìä Migration des Donn√©es

### Option 1: Migration Automatique (Recommand√©e)

```bash
# 1. T√©l√©charger le script de migration
curl -O https://raw.githubusercontent.com/chrisboulet/geekblog/main/scripts/migrate_to_optimized.sh
chmod +x migrate_to_optimized.sh

# 2. Ex√©cuter la migration
./migrate_to_optimized.sh

# Le script va:
# - Exporter les donn√©es PostgreSQL
# - Arr√™ter l'ancienne version
# - D√©marrer la nouvelle version
# - Importer les donn√©es dans SQLite
# - Valider la migration
```

### Option 2: Migration √âtape par √âtape

#### √âtape 1: Export PostgreSQL

```bash
# Export avec format custom
docker exec geekblog_db pg_dump \
  -U geekblog \
  -d geekblogdb \
  --format=custom \
  --no-owner \
  --no-privileges \
  > geekblog_export.dump

# Export en SQL pour v√©rification
docker exec geekblog_db pg_dump \
  -U geekblog \
  -d geekblogdb \
  --inserts \
  --column-inserts \
  > geekblog_export.sql
```

#### √âtape 2: Conversion PostgreSQL ‚Üí SQLite

```python
# Script Python de conversion
import sqlite3
import psycopg2
import json
from datetime import datetime

def migrate_data():
    # Connexion PostgreSQL
    pg_conn = psycopg2.connect(
        host="localhost",
        port=5432,
        database="geekblogdb",
        user="geekblog",
        password="geekblog_password"
    )
    
    # Connexion SQLite
    sqlite_conn = sqlite3.connect("geekblog_migrated.db")
    
    # Cr√©er les tables SQLite
    with open("schema.sql", "r") as f:
        sqlite_conn.executescript(f.read())
    
    # Migrer les projets
    pg_cursor = pg_conn.cursor()
    pg_cursor.execute("SELECT * FROM projects")
    projects = pg_cursor.fetchall()
    
    sqlite_cursor = sqlite_conn.cursor()
    for project in projects:
        sqlite_cursor.execute("""
            INSERT INTO projects (id, title, description, goal, status, created_at, updated_at)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, project)
    
    # Migrer les t√¢ches
    pg_cursor.execute("SELECT * FROM tasks")
    tasks = pg_cursor.fetchall()
    
    for task in tasks:
        sqlite_cursor.execute("""
            INSERT INTO tasks (id, project_id, title, description, status, created_at, updated_at)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, task)
    
    sqlite_conn.commit()
    print("Migration completed successfully!")

if __name__ == "__main__":
    migrate_data()
```

#### √âtape 3: D√©ploiement Nouvelle Version

```bash
# 1. Arr√™ter l'ancienne version
docker-compose down

# 2. Cr√©er le volume de donn√©es
mkdir -p ./data

# 3. Copier la base SQLite migr√©e
cp geekblog_migrated.db ./data/geekblog.db

# 4. D√©marrer la nouvelle version
docker run -d \
  --name geekblog-optimized \
  -p 8000:8000 \
  -v $(pwd)/data:/app/data \
  -e GROQ_API_KEY=${GROQ_API_KEY} \
  geekblog:latest
```

---

## üõ†Ô∏è Migration Manuelle

### Si vous pr√©f√©rez le contr√¥le total

#### 1. Pr√©parer l'environnement

```bash
# Cr√©er r√©pertoire de travail
mkdir geekblog_migration
cd geekblog_migration

# T√©l√©charger les outils de migration
curl -O https://raw.githubusercontent.com/chrisboulet/geekblog/main/scripts/pg_to_sqlite.py
curl -O https://raw.githubusercontent.com/chrisboulet/geekblog/main/scripts/validate_migration.py
```

#### 2. Export des sch√©mas

```bash
# Sch√©ma PostgreSQL
docker exec geekblog_db pg_dump \
  -U geekblog \
  -d geekblogdb \
  --schema-only \
  > schema_pg.sql

# Donn√©es seulement
docker exec geekblog_db pg_dump \
  -U geekblog \
  -d geekblogdb \
  --data-only \
  --inserts \
  > data_pg.sql
```

#### 3. Conversion manuelle

```sql
-- Adapter les types PostgreSQL ‚Üí SQLite
-- schema_sqlite.sql

-- Remplacer:
-- SERIAL ‚Üí INTEGER PRIMARY KEY AUTOINCREMENT
-- TIMESTAMP ‚Üí TEXT
-- BOOLEAN ‚Üí INTEGER
-- TEXT[] ‚Üí TEXT (JSON)

CREATE TABLE projects (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    title TEXT NOT NULL,
    description TEXT,
    goal TEXT,
    status TEXT DEFAULT 'active',
    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
    updated_at TEXT DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE tasks (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    project_id INTEGER REFERENCES projects(id),
    title TEXT NOT NULL,
    description TEXT,
    status TEXT DEFAULT 'pending',
    created_by_ai INTEGER DEFAULT 0,
    last_updated_by_ai_at TEXT,
    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
    updated_at TEXT DEFAULT CURRENT_TIMESTAMP
);
```

#### 4. Import dans SQLite

```bash
# Cr√©er la nouvelle base
sqlite3 geekblog.db < schema_sqlite.sql

# Adapter et importer les donn√©es
python3 pg_to_sqlite.py \
  --source data_pg.sql \
  --target geekblog.db \
  --validate
```

---

## ‚úÖ Validation

### Script de Validation Compl√®te

```bash
# validate_migration.sh
#!/bin/bash

echo "=== Validation Migration GeekBlog ==="

# 1. V√©rifier que le nouveau container tourne
if ! docker ps | grep -q geekblog-optimized; then
    echo "‚ùå Container optimis√© non trouv√©"
    exit 1
fi

# 2. Test health endpoint
if ! curl -f http://localhost:8000/health > /dev/null 2>&1; then
    echo "‚ùå Health check failed"
    exit 1
fi

# 3. Comparer le nombre de projets
OLD_PROJECTS=$(grep "INSERT INTO projects" data_pg.sql | wc -l)
NEW_PROJECTS=$(curl -s http://localhost:8000/api/v1/projects | jq length)

if [ "$OLD_PROJECTS" != "$NEW_PROJECTS" ]; then
    echo "‚ùå Nombre de projets diff√©rent: $OLD_PROJECTS ‚Üí $NEW_PROJECTS"
    exit 1
fi

# 4. Comparer le nombre de t√¢ches
OLD_TASKS=$(grep "INSERT INTO tasks" data_pg.sql | wc -l)
NEW_TASKS=$(curl -s http://localhost:8000/api/v1/tasks | jq length)

if [ "$OLD_TASKS" != "$NEW_TASKS" ]; then
    echo "‚ùå Nombre de t√¢ches diff√©rent: $OLD_TASKS ‚Üí $NEW_TASKS"
    exit 1
fi

# 5. Test fonctionnel: cr√©er un projet
TEST_PROJECT=$(curl -s -X POST http://localhost:8000/api/v1/projects \
  -H "Content-Type: application/json" \
  -d '{"title":"Test Migration","description":"Test post-migration"}')

if ! echo "$TEST_PROJECT" | jq -e '.id' > /dev/null; then
    echo "‚ùå Impossible de cr√©er un nouveau projet"
    exit 1
fi

echo "‚úÖ Migration valid√©e avec succ√®s!"
echo "   - Projets: $NEW_PROJECTS"
echo "   - T√¢ches: $NEW_TASKS"
echo "   - Test fonctionnel: OK"
```

---

## üîô Rollback

### En cas de probl√®me

```bash
# 1. Arr√™ter la nouvelle version
docker stop geekblog-optimized
docker rm geekblog-optimized

# 2. Restaurer l'ancienne version
docker-compose -f docker-compose.yml.backup up -d

# 3. Attendre que les services d√©marrent
sleep 30

# 4. Restaurer les donn√©es PostgreSQL si n√©cessaire
docker exec -i geekblog_db psql -U geekblog -d geekblogdb < backup_YYYYMMDD_HHMMSS.sql

# 5. V√©rifier
curl http://localhost:8000/api/v1/projects
```

### Plan de Rollback Automatis√©

```bash
# rollback.sh
#!/bin/bash
echo "Rollback vers l'ancienne version..."

# Backup des nouvelles donn√©es au cas o√π
docker exec geekblog-optimized sqlite3 /app/data/geekblog.db ".backup '/tmp/optimized_backup.db'"
docker cp geekblog-optimized:/tmp/optimized_backup.db ./

# Arr√™t nouvelle version
docker stop geekblog-optimized
docker rm geekblog-optimized

# Restauration ancienne version
docker-compose -f docker-compose.yml.backup up -d

echo "Rollback termin√©. V√©rifiez http://localhost:8000"
```

---

## ‚ùì FAQ

### Q: Puis-je faire une migration en zero-downtime?

**R**: Partiellement. Vous pouvez:
1. D√©marrer la nouvelle version sur port 8001
2. Migrer les donn√©es
3. Basculer le reverse proxy
4. Arr√™ter l'ancienne version

### Q: Les jobs Celery en cours sont-ils perdus?

**R**: Les jobs en cours seront perdus. Planifiez la migration pendant une p√©riode creuse.

### Q: Puis-je revenir √† PostgreSQL plus tard?

**R**: Oui, nous fournirons un script SQLite ‚Üí PostgreSQL si n√©cessaire.

### Q: La nouvelle version supporte-t-elle le clustering?

**R**: Non, elle est optimis√©e pour single-user. Pour le clustering, gardez l'ancienne architecture.

### Q: Comment migrer si j'ai des customizations?

**R**: Contactez-nous avec vos modifications, nous vous aiderons √† les adapter.

### Q: Et si ma base PostgreSQL est tr√®s grande (>1GB)?

**R**: SQLite peut g√©rer plusieurs GB. Testez d'abord sur une copie.

---

## üìû Support Migration

Pour assistance durant la migration:
- Issues: https://github.com/chrisboulet/geekblog/issues
- Tag: `migration`
- Include: logs, version actuelle, taille des donn√©es

---

**Migration GeekBlog - Votre Guide Complet vers l'Optimisation** üöÄ